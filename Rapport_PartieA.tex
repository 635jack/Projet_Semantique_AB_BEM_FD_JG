\documentclass[12pt,a4paper]{article}
\usepackage[utf8]{inputenc}
\usepackage[french]{babel}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{enumitem}
\usepackage{fancyhdr}
\usepackage{xcolor}
\usepackage{listings}

\geometry{margin=2.5cm}

% Configuration des liens
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Rapport Final Partie A - Preprocessing},
    pdfauthor={Jacques Gastebois},
}

% Configuration du code
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    backgroundcolor=\color{gray!10},
    keywordstyle=\color{blue},
    commentstyle=\color{green!50!black},
    stringstyle=\color{red},
    language=Python
}

% En-tête et pied de page
\pagestyle{fancy}
\fancyhf{}
\rhead{Partie A : Preprocessing \& Analyse}
\lhead{Projet Sémantique}
\cfoot{\thepage}

\title{\textbf{Projet Knowledge Extraction}\\
\large Partie A : Preprocessing, Analyse Statistique et Justification des Choix\\
\vspace{0.5cm}
\normalsize Rapport Technique Final}

\author{
Jacques Gastebois\\
\small Master 2 VMI - Université Paris Cité\\
\small IFLCE085 - Recherche et extraction sémantique
}

\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Ce rapport synthétise les travaux réalisés pour la Partie A du projet. Il détaille le pipeline de preprocessing appliqué au corpus NER (2221 phrases), présente une analyse statistique des données, et justifie les choix techniques (nettoyage, lemmatization) en analysant leurs avantages, inconvénients et impacts sur les tâches d'extraction d'entités (Partie B) et de relations (Partie C).
\end{abstract}

\tableofcontents
\newpage

\section{Introduction}
Le projet vise à extraire des connaissances structurées à partir d'un corpus de textes non structurés. La première étape cruciale est le \textbf{preprocessing}, qui transforme les données brutes en un format exploitable pour les algorithmes d'apprentissage automatique.

\subsection{Le Corpus}
Le dataset utilisé (\texttt{data.csv}) est constitué de \textbf{2221 phrases} annotées pour la reconnaissance d'entités nommées (NER).
\begin{itemize}
    \item \textbf{Format d'entrée} : CSV avec colonnes \texttt{id}, \texttt{words}, \texttt{ner\_tags}, \texttt{text}.
    \item \textbf{Contenu} : Textes encyclopédiques/biographiques.
    \item \textbf{Annotations} : Tags BIO (Begin, Inside, Outside) pour les entités Personnes (PER), Lieux (LOC), Organisations (ORG), etc.
\end{itemize}

\section{Méthodologie de Preprocessing}

Contrairement à une approche classique de "Bag of Words" (TF-IDF), nous avons opté pour une approche de \textbf{preprocessing enrichi} qui préserve la structure séquentielle des données, essentielle pour le NER.

\subsection{Pipeline Mis en Place}
Le traitement a été réalisé en Python (via un notebook Jupyter) et comprend les étapes suivantes :

\begin{enumerate}
    \item \textbf{Nettoyage (\texttt{cleaned\_text})} :
    \begin{itemize}
        \item Conversion en minuscules (lowercase) pour réduire la dimensionnalité.
        \item Suppression des caractères spéciaux non alphanumériques (sauf espaces).
        \item Normalisation des espaces multiples.
    \end{itemize}
    
    \item \textbf{Lemmatization (\texttt{lemmatized\_text})} :
    \begin{itemize}
        \item Utilisation de la librairie \textbf{spaCy} (modèle \texttt{en\_core\_web\_sm}).
        \item Transformation des mots en leur forme canonique (ex: "running" $\rightarrow$ "run", "better" $\rightarrow$ "good").
    \end{itemize}
    
    \item \textbf{Enrichissement du Dataset} :
    \begin{itemize}
        \item Au lieu de créer des matrices séparées, nous avons ajouté les colonnes \texttt{cleaned\_text} et \texttt{lemmatized\_text} directement au fichier original.
        \item \textbf{Sortie} : \texttt{data\_preprocessed.csv}.
    \end{itemize}
\end{enumerate}

\section{Analyse Statistique du Corpus}

L'analyse réalisée dans le notebook \texttt{PartieA\_Analyse\_Statistique.ipynb} a révélé les caractéristiques suivantes :

\subsection{Volumétrie et Longueur}
\begin{itemize}
    \item \textbf{Nombre de phrases} : 2221.
    \item \textbf{Longueur moyenne} : $\sim$24 mots par phrase.
    \item \textbf{Impact du preprocessing} : La lemmatization réduit la taille du vocabulaire d'environ \textbf{15\% à 25\%}, ce qui densifie l'information sans perte majeure de sens.
\end{itemize}

\subsection{Distribution des Entités (NER)}
L'analyse des tags \texttt{ner\_tags} montre un déséquilibre de classe classique :
\begin{itemize}
    \item Le tag \textbf{O (Other)} est ultra-majoritaire (tokens non-entités).
    \item Les entités \textbf{B-PER}, \textbf{B-LOC}, \textbf{B-ORG} sont présentes mais minoritaires.
    \item \textbf{Conséquence} : Les modèles devront gérer ce déséquilibre (ex: via des fonctions de perte pondérées).
\end{itemize}

\section{Analyse Critique des Choix}

\subsection{Choix 1 : Lemmatization vs Stemming}
\begin{itemize}
    \item \textbf{Choix} : Lemmatization (spaCy).
    \item \textbf{Avantages} : Produit des mots réels (formes dictionnaire), préserve mieux le sens sémantique pour l'extraction de relations (Partie C). Plus précis que le stemming (qui tronque brutalement).
    \item \textbf{Inconvénients} : Plus coûteux en temps de calcul. Peut perdre certaines nuances flexionnelles (temps des verbes) utiles pour la temporalité.
\end{itemize}

\subsection{Choix 2 : Lowercasing (Mise en minuscule)}
\begin{itemize}
    \item \textbf{Choix} : Tout mettre en minuscule dans \texttt{cleaned\_text}.
    \item \textbf{Avantages} : Réduit drastiquement la taille du vocabulaire. Associe "Apple" (fruit) et "apple" (fruit).
    \item \textbf{Inconvénients (Critique pour le NER)} : \textbf{Perte de l'information de capitalisation}, qui est un indice crucial pour détecter les entités nommées (ex: "Apple" l'entreprise vs "apple" le fruit).
    \item \textbf{Mitigation} : Nous avons conservé la colonne \texttt{text} originale. Les modèles NER modernes (BERT, etc.) ou les features manuelles peuvent utiliser le texte brut pour récupérer la casse.
\end{itemize}

\subsection{Choix 3 : Conservation de la Structure Séquentielle}
\begin{itemize}
    \item \textbf{Choix} : Ne pas vectoriser en TF-IDF (Bag of Words) pour l'export final.
    \item \textbf{Avantages} : Indispensable pour le NER et l'extraction de relations qui dépendent de l'ordre des mots et du contexte local. Permet l'utilisation de modèles de Deep Learning (RNN, Transformers).
    \item \textbf{Inconvénients} : Fichiers texte plus volumineux que des matrices creuses.
\end{itemize}

\section{Impact sur la Suite du Projet}

\subsection{Impact sur la Partie II (NER)}
Le preprocessing fournit une base propre (\texttt{lemmatized\_text}) qui généralise mieux. Cependant, pour maximiser les scores F1, il sera probablement nécessaire d'utiliser :
\begin{enumerate}
    \item Le \textbf{texte original} pour les features de capitalisation.
    \item Le \textbf{texte lemmatisé} pour les embeddings sémantiques (Word2Vec/GloVe) afin de regrouper les variantes d'un même mot.
\end{enumerate}

\subsection{Impact sur la Partie C (Extraction de Relations)}
L'extraction de relations (triplets Sujet-Verbe-Objet) bénéficie grandement de la lemmatization :
\begin{itemize}
    \item Elle normalise les verbes (ex: "est né", "naquit" $\rightarrow$ "naître"), simplifiant la détection de patterns de relations.
    \item Elle réduit la complexité des arbres de dépendance syntaxique.
\end{itemize}

\section{Conclusion}
Le preprocessing réalisé est un compromis entre \textbf{réduction de bruit} (nettoyage, lemmatization) et \textbf{préservation de l'information} (conservation du texte brut et de la séquence). Ce socle de données enrichi (\texttt{data\_preprocessed.csv}) est robuste et adapté aux défis des parties suivantes : la reconnaissance fine d'entités et l'extraction complexe de relations sémantiques.

\end{document}
